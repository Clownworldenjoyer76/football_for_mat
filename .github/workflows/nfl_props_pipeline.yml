name: NFL Props Pipeline

on:
  workflow_dispatch:
    inputs:
      pull_odds:
        description: "Pull odds via API (if script present)? 1=yes, 0=no"
        required: true
        default: "0"
      forecast_season:
        description: "Pregame season (e.g., 2025) — leave blank to skip"
        required: false
        default: ""
      forecast_week:
        description: "Pregame week (e.g., 1) — leave blank to skip"
        required: false
        default: ""

permissions:
  contents: write

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      TZ: America/New_York
      PULL_ODDS: ${{ github.event.inputs.pull_odds }}
      FORECAST_SEASON: ${{ github.event.inputs.forecast_season }}
      FORECAST_WEEK: ${{ github.event.inputs.forecast_week }}
      PYTHONUNBUFFERED: "1"
      LOG_DIR: logs/ci
      LOG_FILE: logs/ci/run.log

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Prep log directory
        run: |
          set -Eeuo pipefail
          mkdir -p "$LOG_DIR"
          echo "# NFL Props Pipeline log" > "$LOG_FILE"
          echo "run_id=${{ github.run_id }}" >> "$LOG_FILE"
          echo "run_number=${{ github.run_number }}" >> "$LOG_FILE"
          echo "ref=${{ github.ref }}" >> "$LOG_FILE"
          echo "ts=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> "$LOG_FILE"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install deps
        run: |
          set -Eeuo pipefail
          {
            python -m pip install --upgrade pip
            if [ -f requirements.txt ]; then
              pip install -r requirements.txt
            else
              pip install pandas numpy nfl_data_py scikit-learn lightgbm scipy requests joblib lxml html5lib
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # --- Detect & back up existing roster (optional seed) ---
      - name: Detect and back up existing roster
        run: |
          set -Eeuo pipefail
          {
            mkdir -p tmp
            if [ -f data/raw/nflverse/rosters_latest.csv.gz ]; then
              echo "HAVE_SEEDED_ROSTER=1" >> $GITHUB_ENV
              cp -f data/raw/nflverse/rosters_latest.csv.gz tmp/rosters_latest.seed.gz
              echo "Found pre-seeded roster; backed up to tmp/rosters_latest.seed.gz"
            else
              echo "HAVE_SEEDED_ROSTER=0" >> $GITHUB_ENV
              echo "No pre-seeded roster detected"
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # --- R setup & rosters (skip if rosters already exist) ---
      - name: Set up R
        if: ${{ hashFiles('data/raw/nflverse/rosters_latest.csv.gz') == '' }}
        uses: r-lib/actions/setup-r@v2

      - name: Set up R dependencies
        if: ${{ hashFiles('data/raw/nflverse/rosters_latest.csv.gz') == '' }}
        uses: r-lib/actions/setup-r-dependencies@v2
        with:
          packages: |
            any::remotes
            any::nflreadr

      - name: Pull rosters via nflreadr (R) — latest only (2024+)
        if: ${{ hashFiles('data/raw/nflverse/rosters_latest.csv.gz') == '' }}
        run: |
          set -Eeuo pipefail
          {
            Rscript -e "yrs <- 2024:as.integer(format(Sys.Date(), '%Y'));
                        df <- nflreadr::load_rosters(yrs);
                        dir.create('data/raw/nflverse', recursive=TRUE, showWarnings=FALSE);
                        fn <- 'data/raw/nflverse/rosters_latest.csv.gz';
                        write.csv(df, gzfile(fn), row.names=FALSE)"
          } 2>&1 | tee -a "$LOG_FILE"

      # --- Restore pre-seeded roster if changed ---
      - name: Restore pre-seeded roster (if backed up)
        if: ${{ env.HAVE_SEEDED_ROSTER == '1' }}
        run: |
          set -Eeuo pipefail
          {
            if [ -f tmp/rosters_latest.seed.gz ]; then
              cp -f tmp/rosters_latest.seed.gz data/raw/nflverse/rosters_latest.csv.gz
              echo "Restored pre-seeded roster after data pulls."
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # ===== Core pulls (PBP + canonicalize WEEKLY/ROSTERS) =====
      - name: Step 01 (Pull NFL data and canonicalize)
        run: |
          set -Eeuo pipefail
          {
            YEND=$(date +%Y)
            if [ -f scripts/01_pull_nflverse.py ]; then
              python scripts/01_pull_nflverse.py --start 2024 --end "$YEND"
            elif [ -f scripts/01_pull_nflverse_chunked.py ]; then
              python scripts/01_pull_nflverse_chunked.py --start 2024 --end "$YEND" --chunk-years 2
            else
              echo "ERROR: no Step 01 script found" >&2
              exit 1
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # --- Finalize WEEKLY/ROSTERS tiny artifacts (no network) ---
      - name: Finalize weekly/rosters tiny artifacts (no network)
        run: |
          set -Eeuo pipefail
          {
            python - <<'PY'
import runpy
g = runpy.run_path('scripts/01_pull_nflverse.py')
g['weekly_canonicalize']()
g['rosters_canonicalize']()
PY
          } 2>&1 | tee -a "$LOG_FILE"

      # ===== Optional NGS ingestion (temporarily disabled) =====
      - name: Step 01b (Pull NGS - temporarily disabled)
        run: |
          set -Eeuo pipefail
          { echo "NOTE: NGS ingestion disabled — circle back when feed is live."; } 2>&1 | tee -a "$LOG_FILE"

      # --- Upload raw snapshot (artifact)
      - name: Upload raw snapshot (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: nflverse-raw-${{ github.run_id }}
          path: |
            data/raw/nflverse/play_by_play_latest.csv.gz
            data/raw/nflverse/pbp_latest.parquet
            data/raw/nflverse/pbp_latest.head100.csv.gz
            data/raw/nflverse/manifest_latest.csv.gz
            data/raw/nflverse/weekly_latest.csv.gz
            data/raw/nflverse/weekly_latest.parquet
            data/raw/nflverse/weekly_manifest_latest.csv.gz
            data/raw/nflverse/rosters_latest.csv.gz
            data/raw/nflverse/rosters_latest.parquet
            data/raw/nflverse/rosters_manifest_latest.csv.gz

      # ===== Features =====
      - name: Step 02 (Build features)
        run: |
          set -Eeuo pipefail
          {
            if [ -f scripts/02_build_features.py ]; then
              python scripts/02_build_features.py
              # capture quick schema snapshot to aid debugging
              if [ -f data/features/weekly_clean.csv.gz ]; then
                python - <<'PY'
import pandas as pd, gzip, io, json
df = pd.read_csv('data/features/weekly_clean.csv.gz', nrows=1000)
open('logs/ci/weekly_clean_cols.json','w').write(json.dumps(list(df.columns), indent=2))
open('logs/ci/weekly_clean_head.json','w').write(df.head(3).to_json(orient='records'))
PY
              fi
            else
              echo "ERROR: scripts/02_build_features.py not found" >&2
              exit 1
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # ===== Train =====
      - name: Step 03 (Train models)
        run: |
          set -Eeuo pipefail
          {
            if [ -f scripts/03_train_models.py ]; then
              python scripts/03_train_models.py
            else
              echo "ERROR: scripts/03_train_models.py not found" >&2
              exit 1
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # ===== Predict (optional) =====
      - name: Step 04 (Pregame predictions)
        run: |
          set -Eeuo pipefail
          {
            if [ -f scripts/04_predict_pregame.py ]; then
              python scripts/04_predict_pregame.py --season "${FORECAST_SEASON}" --week "${FORECAST_WEEK}"
            else
              echo "SKIP: scripts/04_predict_pregame.py not found"
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # ===== Upload models/metrics and predictions as artifacts (always) =====
      - name: Upload models & metrics (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: models-and-metrics-${{ github.run_id }}
          path: |
            models/pregame/*.joblib
            output/models/metrics_summary.csv
          if-no-files-found: warn

      - name: Upload predictions (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: predictions-${{ github.run_id }}
          path: |
            data/predictions/pregame/*.csv.gz
            output/predictions/pregame/*.csv.gz
          if-no-files-found: warn

      # ===== Commit outputs (raw + models + metrics + predictions) =====
      - name: Commit outputs
        env:
          GH_USER_NAME: "github-actions[bot]"
          GH_USER_EMAIL: "github-actions[bot]@users.noreply.github.com"
        run: |
          set -Eeuo pipefail
          {
            git config user.name "$GH_USER_NAME"
            git config user.email "$GH_USER_EMAIL"

            mkdir -p data/raw/nflverse
            git add -A -f data/raw/nflverse
            git add -A -f models/pregame
            git add -A -f output/models
            git add -A -f output/predictions
            git add -A -f data/predictions

            if ! git diff --staged --quiet; then
              git commit -m "CI: add/update artifacts (raw/models/metrics/predictions)"
              # safer rebase with autostash; then 3 retry pushes
              git pull --rebase --autostash origin ${{ github.ref_name }} || true
              for i in 1 2 3; do
                git push origin HEAD:${{ github.ref_name }} && break || sleep 5
              done
            else
              echo "No changes to commit."
            fi
          } 2>&1 | tee -a "$LOG_FILE"

      # ===== Always create a concise summary and upload logs =====
      - name: Write run summary (always)
        if: always()
        run: |
          set -Eeuo pipefail
          {
            echo "## NFL Props Pipeline — Run ${{ github.run_number }}"            >  logs/ci/_summary.md
            echo ""                                                             >> logs/ci/_summary.md
            echo "- Ref: \`${{ github.ref }}\`"                                 >> logs/ci/_summary.md
            echo "- Season: \`${{ env.FORECAST_SEASON || '' }}\`"               >> logs/ci/_summary.md
            echo "- Week: \`${{ env.FORECAST_WEEK || '' }}\`"                   >> logs/ci/_summary.md
            echo "- Finished: \`$(date -u +%Y-%m-%dT%H:%M:%SZ)\`"               >> logs/ci/_summary.md
            echo ""                                                             >> logs/ci/_summary.md

            if [ -f output/models/metrics_summary.csv ]; then
              echo "### Models/metrics present"                                 >> logs/ci/_summary.md
              tail -n +1 output/models/metrics_summary.csv | head -n 10         >> logs/ci/_summary.md || true
              echo ""                                                           >> logs/ci/_summary.md
            else
              echo "### Models/metrics missing"                                 >> logs/ci/_summary.md
            fi

            if compgen -G "output/predictions/pregame/*.csv.gz" > /dev/null; then
              echo "### Predictions created"                                   >> logs/ci/_summary.md
              ls -lh output/predictions/pregame/*.csv.gz                      >> logs/ci/_summary.md
            else
              echo "### Predictions not created"                               >> logs/ci/_summary.md
            fi

            echo ""                                                            >> logs/ci/_summary.md
            echo "### Tail of pipeline log"                                    >> logs/ci/_summary.md
            tail -n 200 "$LOG_FILE"                                            >> logs/ci/_summary.md || true

            cat logs/ci/_summary.md >> "$GITHUB_STEP_SUMMARY"
          } 2>&1 | tee -a "$LOG_FILE"

      - name: Upload logs (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_id }}
          path: |
            logs/ci/run.log
            logs/ci/_summary.md
            logs/ci/weekly_clean_cols.json
            logs/ci/weekly_clean_head.json
          if-no-files-found: warn
