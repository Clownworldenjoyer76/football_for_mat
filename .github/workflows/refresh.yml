name: Weekly Data Refresh

on:
  schedule:
    - cron: "0 17 * * 2"   # 17:00 UTC = 12:00 PM ET (Tuesday)
  workflow_dispatch:
    inputs:
      season:
        description: "Season to refresh (e.g., 2025)"
        required: false
        default: "2025"

permissions:
  contents: write

jobs:
  refresh-data:
    runs-on: ubuntu-latest
    env:
      SEASON: ${{ inputs.season || '2025' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # ---------- R: depth charts via nflreadr ----------
      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3.3'

      - name: Install R deps (nflreadr)
        uses: r-lib/actions/setup-r-dependencies@v2
        with:
          packages: |
            any::nflreadr

      - name: Fetch depth charts (CSV then gzip)
        run: |
          Rscript - <<'RSCRIPT'
          dir.create("data/raw/nflverse", recursive = TRUE, showWarnings = FALSE)
          suppressPackageStartupMessages(library(nflreadr))
          dc <- nflreadr::load_depth_charts()
          if (nrow(dc) == 0) stop("No depth chart rows returned")
          out_csv <- file.path("data/raw/nflverse","depth_charts.csv")
          write.csv(dc, out_csv, row.names = FALSE)
          cat("Wrote:", out_csv, "\n")
          RSCRIPT
          gzip -f data/raw/nflverse/depth_charts.csv

      # ---------- Python pulls ----------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install pyarrow fastparquet lxml || true

      - name: Pull core NFL datasets (pbp/weekly/rosters/depth)
        env:
          NFLVERSE_WEEKLY_URL_TPL: "https://github.com/nflverse/nflverse-data/releases/download/weekly/weekly_{year}.csv.gz"
          NFLVERSE_WEEKLY_LATEST: "https://github.com/nflverse/nflverse-data/releases/download/weekly/weekly_latest.csv.gz"
          NFLVERSE_ROSTERS_LATEST: "https://github.com/nflverse/nflverse-data/releases/download/rosters/rosters_latest.csv.gz"
          NFLVERSE_DEPTH_LATEST: "https://github.com/nflverse/nflverse-data/releases/download/depth/depth_latest.csv.gz"
          NFLVERSE_PBP_LATEST: "https://github.com/nflverse/nflverse-data/releases/download/pbp/play_by_play_latest.csv.gz"
          NFLVERSE_SCHEDULES_LATEST: "https://github.com/nflverse/nflverse-data/releases/download/schedules/schedules_latest.csv.gz"
          NFLVERSE_MANIFEST_LATEST: "https://github.com/nflverse/nflverse-data/releases/download/manifest/manifest_latest.csv.gz"
        run: |
          set -e
          SEASON="${{ env.SEASON }}"
          # Pull all the "latest" files you already use, plus the *explicit* weekly_<SEASON>.csv.gz
          python scripts/01_pull_nflverse.py --season "$SEASON" --dl-weekly --dl-rosters --dl-depth --dl-pbp

      # ---------- Build data/weekly/latest.csv from the season-specific file (hard requirement) ----------
      - name: Build data/weekly/latest.csv for requested season
        run: |
          set -e
          mkdir -p data/weekly
          SEASON="${{ env.SEASON }}"
          SRC="data/raw/nflverse/weekly_${SEASON}.csv.gz"
          if [ ! -f "$SRC" ]; then
            echo "ERROR: $SRC not found. The weekly file for season $SEASON did not download."
            echo "Directory listing of data/raw/nflverse:"
            ls -lh data/raw/nflverse || true
            exit 1
          fi
          zcat "$SRC" > data/weekly/latest.csv
          echo "âœ“ Wrote data/weekly/latest.csv from $SRC"
          head -20 data/weekly/latest.csv || true

      # ---------- Verify the season actually matches ----------
      - name: Verify season/week coverage in weekly/latest.csv
        run: |
          set -e
          python - <<'PY'
          import pandas as pd, sys, os
          want = int(os.getenv("SEASON", "2025"))
          df = pd.read_csv("data/weekly/latest.csv")
          if "season" not in df.columns:
              print("ERROR: 'season' column missing in weekly/latest.csv", file=sys.stderr)
              sys.exit(1)
          mx = int(df["season"].max())
          mn = int(df["season"].min())
          print("min season:", mn, "max season:", mx)
          if mx != want:
              print(f"ERROR: weekly/latest.csv max(season)={mx} != requested {want}", file=sys.stderr)
              sys.exit(1)
          print("OK: weekly/latest.csv covers requested season", want)
          PY

      # ---------- Commit & push ----------
      - name: Commit & push updated data
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Stage files (guard each so a missing path doesn't fail the job)
          git add -f data/raw/nflverse        2>/dev/null || true
          git add -f data/raw/weather         2>/dev/null || true
          git add -f data/raw/injuries        2>/dev/null || true
          git add -f data/odds                2>/dev/null || true
          git add -f data/weekly/latest.csv   2>/dev/null || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "chore(data): weekly refresh (season ${SEASON}) [skip ci]"
          git fetch origin
          git pull --rebase origin main || true
          git push
