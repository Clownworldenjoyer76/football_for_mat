name: Weekly Data Refresh

on:
  schedule:
    - cron: "0 17 * * 2"   # 17:00 UTC = 12:00 PM ET (Tuesday)
  workflow_dispatch:
    inputs:
      season:
        description: "Season context (optional, for your scripts)"
        required: false
        default: "2025"

permissions:
  contents: write

jobs:
  refresh-data:
    runs-on: ubuntu-latest
    env:
      # Exposed in case your scripts read it, but we are NOT calling dead URLs anymore.
      SEASON: ${{ inputs.season || '2025' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # ---------- R: depth charts via nflreadr ----------
      - name: Set up R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3.3'

      - name: Install R deps (nflreadr)
        uses: r-lib/actions/setup-r-dependencies@v2
        with:
          packages: |
            any::nflreadr

      - name: Fetch depth charts (CSV then gzip)
        run: |
          Rscript - <<'RSCRIPT'
          dir.create("data/raw/nflverse", recursive = TRUE, showWarnings = FALSE)
          suppressPackageStartupMessages(library(nflreadr))
          dc <- nflreadr::load_depth_charts()
          if (nrow(dc) == 0) stop("No depth chart rows returned")
          out_csv <- file.path("data/raw/nflverse","depth_charts.csv")
          write.csv(dc, out_csv, row.names = FALSE)
          cat("Wrote:", out_csv, "\n")
          RSCRIPT
          gzip -f data/raw/nflverse/depth_charts.csv

      # ---------- Python pulls (no external URLs in env; let your script handle it) ----------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install pyarrow fastparquet lxml || true
          # if your scripts require requests/pandas:
          pip install pandas requests || true

      - name: Pull & canonicalize nflverse datasets (pbp/weekly/rosters/depth)
        run: |
          set -e
          # This script already: downloads/updates PBP; optionally downloads weekly/rosters/depth
          # and ALWAYS canonicalizes to *_latest.csv.gz and *_latest.parquet
          python scripts/01_pull_nflverse.py --dl-weekly --dl-rosters --dl-depth

          echo "---- Canonical files present in data/raw/nflverse ----"
          ls -lh data/raw/nflverse || true

      # ---------- Build data/weekly/latest.csv from canonical weekly_latest.csv.gz ----------
      - name: Build data/weekly/latest.csv from canonical weekly_latest.csv.gz
        run: |
          set -e
          mkdir -p data/weekly
          SRC="data/raw/nflverse/weekly_latest.csv.gz"
          if [ ! -f "$SRC" ]; then
            echo "ERROR: $SRC not found. Your 01_pull_nflverse.py did not produce the canonical weekly file."
            echo "Listing of data/raw/nflverse for debugging:"
            ls -lh data/raw/nflverse || true
            exit 1
          fi
          zcat "$SRC" > data/weekly/latest.csv
          echo "âœ“ Wrote data/weekly/latest.csv from $SRC"
          head -20 data/weekly/latest.csv || true

      # ---------- Verify the weekly file actually advanced ----------
      - name: Verify season/week coverage in weekly/latest.csv
        run: |
          set -e
          python - <<'PY'
          import pandas as pd
          df = pd.read_csv("data/weekly/latest.csv")
          if "season" not in df.columns or "week" not in df.columns:
              raise SystemExit("weekly/latest.csv missing 'season' and/or 'week' columns")
          print("min season:", int(df["season"].min()))
          print("max season:", int(df["season"].max()))
          print("max week per season:", {int(k): int(v) for k,v in df.groupby("season")["week"].max().to_dict().items()})
          PY

      # ---------- Commit & push ----------
      - name: Commit & push updated data
        run: |
          set -e
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Stage files (guard each so a missing path doesn't fail the job)
          git add -f data/raw/nflverse        2>/dev/null || true
          git add -f data/raw/weather         2>/dev/null || true
          git add -f data/raw/injuries        2>/dev/null || true
          git add -f data/odds                2>/dev/null || true
          git add -f data/weekly/latest.csv   2>/dev/null || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "chore(data): weekly refresh (canonical weekly_latest.csv.gz -> data/weekly/latest.csv) [skip ci]"
          git fetch origin
          git pull --rebase origin main || true
          git push
