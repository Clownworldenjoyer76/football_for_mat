name: NFL Props Pipeline

on:
  workflow_dispatch:
    inputs:
      pull_odds:
        description: "Pull odds via API (if script present)? 1=yes, 0=no"
        required: true
        default: "0"
      forecast_season:
        description: "Pregame season (e.g., 2025) — leave blank to skip"
        required: false
        default: ""
      forecast_week:
        description: "Pregame week (e.g., 1) — leave blank to skip"
        required: false
        default: ""

permissions:
  contents: write

concurrency:
  group: nfl-props-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    env:
      TZ: America/New_York
      PULL_ODDS: ${{ github.event.inputs.pull_odds }}
      FORECAST_SEASON: ${{ github.event.inputs.forecast_season }}
      FORECAST_WEEK: ${{ github.event.inputs.forecast_week }}
      LOG_DIR: output/_logs
      SUMMARY_FILE: output/_logs/summary.txt

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Initialize log directory and summary
        run: |
          set -e
          mkdir -p "$LOG_DIR"
          printf "RUN ID: %s\nREPO: %s\nBRANCH: %s\nDATE: %s\n\n" \
            "${{ github.run_id }}" "${{ github.repository }}" "${{ github.ref_name }}" "$(date -u +"%Y-%m-%d %H:%M:%S UTC")" > "$SUMMARY_FILE"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install deps
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip >>"$LOG_DIR/pip.log" 2>&1
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt >>"$LOG_DIR/pip.log" 2>&1
          else
            pip install pandas numpy nfl_data_py scikit-learn lightgbm scipy requests joblib lxml html5lib >>"$LOG_DIR/pip.log" 2>&1
          fi
        shell: bash
      - name: Note Install deps
        if: always()
        run: |
          if [ "${{ steps.Install_deps.outcome || '' }}" = "failure" ]; then
            echo "[Install deps] FAILED" >> "$SUMMARY_FILE"
          else
            echo "[Install deps] OK" >> "$SUMMARY_FILE"
          fi

      # --- Detect & back up existing roster (optional seed) ---
      - name: Detect and back up existing roster
        run: |
          set -euxo pipefail
          mkdir -p tmp
          if [ -f data/raw/nflverse/rosters_latest.csv.gz ]; then
            echo "HAVE_SEEDED_ROSTER=1" >> $GITHUB_ENV
            cp -f data/raw/nflverse/rosters_latest.csv.gz tmp/rosters_latest.seed.gz
            echo "Found pre-seeded roster; backed up to tmp/rosters_latest.seed.gz" | tee -a "$SUMMARY_FILE"
          else
            echo "HAVE_SEEDED_ROSTER=0" >> $GITHUB_ENV
            echo "No pre-seeded roster detected" | tee -a "$SUMMARY_FILE"
          fi

      # --- R setup & rosters (skip if rosters already exist) ---
      - name: Set up R
        if: ${{ hashFiles('data/raw/nflverse/rosters_latest.csv.gz') == '' }}
        uses: r-lib/actions/setup-r@v2

      - name: Set up R dependencies
        if: ${{ hashFiles('data/raw/nflverse/rosters_latest.csv.gz') == '' }}
        uses: r-lib/actions/setup-r-dependencies@v2
        with:
          packages: |
            any::remotes
            any::nflreadr

      - name: Pull rosters via nflreadr (R) — latest only (2024+)
        if: ${{ hashFiles('data/raw/nflverse/rosters_latest.csv.gz') == '' }}
        run: |
          set -euxo pipefail
          Rscript -e "yrs <- 2024:as.integer(format(Sys.Date(), '%Y'));
                      df <- nflreadr::load_rosters(yrs);
                      dir.create('data/raw/nflverse', recursive=TRUE, showWarnings=FALSE);
                      fn <- 'data/raw/nflverse/rosters_latest.csv.gz';
                      write.csv(df, gzfile(fn), row.names=FALSE)" >>"$LOG_DIR/rosters.log" 2>&1
        shell: bash

      - name: Restore pre-seeded roster (if backed up)
        if: ${{ env.HAVE_SEEDED_ROSTER == '1' }}
        run: |
          set -euxo pipefail
          if [ -f tmp/rosters_latest.seed.gz ]; then
            cp -f tmp/rosters_latest.seed.gz data/raw/nflverse/rosters_latest.csv.gz
            echo "Restored pre-seeded roster after data pulls." | tee -a "$SUMMARY_FILE"
          fi

      # ===== Core pulls (PBP + canonicalize WEEKLY/ROSTERS) =====
      - name: Step 01 (Pull NFL data and canonicalize)
        run: |
          set -euxo pipefail
          YEND=$(date +%Y)
          if [ -f scripts/01_pull_nflverse.py ]; then
            python scripts/01_pull_nflverse.py --start 2024 --end "$YEND" >>"$LOG_DIR/01_pull.log" 2>&1
          elif [ -f scripts/01_pull_nflverse_chunked.py ]; then
            python scripts/01_pull_nflverse_chunked.py --start 2024 --end "$YEND" --chunk-years 2 >>"$LOG_DIR/01_pull.log" 2>&1
          else
            echo "ERROR: no Step 01 script found" | tee -a "$SUMMARY_FILE"
            exit 1
          fi

      - name: Finalize weekly/rosters tiny artifacts (no network)
        run: |
          set -euxo pipefail
          python - <<'PY' >>"$LOG_DIR/01_finalize.log" 2>&1
import runpy
g = runpy.run_path('scripts/01_pull_nflverse.py')
g['weekly_canonicalize']()
g['rosters_canonicalize']()
PY

      # ===== Optional NGS ingestion (temporarily disabled) =====
      - name: Step 01b (Pull NGS - temporarily disabled)
        run: |
          echo "NOTE: NGS ingestion disabled — circle back when feed is live." | tee -a "$SUMMARY_FILE"

      # --- Upload raw snapshot (artifact)
      - name: Upload raw snapshot (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: nflverse-raw-${{ github.run_id }}
          path: |
            data/raw/nflverse/play_by_play_latest.csv.gz
            data/raw/nflverse/pbp_latest.parquet
            data/raw/nflverse/pbp_latest.head100.csv.gz
            data/raw/nflverse/manifest_latest.csv.gz
            data/raw/nflverse/weekly_latest.csv.gz
            data/raw/nflverse/weekly_latest.parquet
            data/raw/nflverse/weekly_manifest_latest.csv.gz
            data/raw/nflverse/rosters_latest.csv.gz
            data/raw/nflverse/rosters_latest.parquet
            data/raw/nflverse/rosters_manifest_latest.csv.gz

      # ===== Step 02 (Features) =====
      - name: Step 02 (Build features)
        run: |
          set -euxo pipefail
          if [ -f scripts/02_build_features.py ]; then
            python scripts/02_build_features.py >>"$LOG_DIR/02_features.log" 2>&1
          else
            echo "ERROR: scripts/02_build_features.py not found" | tee -a "$SUMMARY_FILE"
            exit 1
          fi

      # ===== Step 03 (Train) =====
      - name: Step 03 (Train models)
        run: |
          set -euxo pipefail
          if [ -f scripts/03_train_models.py ]; then
            python scripts/03_train_models.py >>"$LOG_DIR/03_train.log" 2>&1
          else
            echo "ERROR: scripts/03_train_models.py not found" | tee -a "$SUMMARY_FILE"
            exit 1
          fi

      # ===== Step 04 (Predict) =====
      - name: Step 04 (Pregame predictions)
        run: |
          set -euxo pipefail
          if [ -f scripts/04_predict_pregame.py ]; then
            python scripts/04_predict_pregame.py --season "${FORECAST_SEASON}" --week "${FORECAST_WEEK}" >>"$LOG_DIR/04_predict.log" 2>&1
          else
            echo "ERROR: scripts/04_predict_pregame.py not found" | tee -a "$SUMMARY_FILE"
            exit 1
          fi

      # ===== Upload predictions (artifact) =====
      - name: Upload predictions (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: predictions-${{ github.run_id }}
          path: |
            data/predictions/pregame/*.csv.gz
            output/predictions/pregame/*.csv.gz
          if-no-files-found: ignore

      # ===== Commit artifacts (raw + models + metrics + predictions) =====
      - name: Commit outputs
        env:
          GH_USER_NAME: "github-actions[bot]"
          GH_USER_EMAIL: "github-actions[bot]@users.noreply.github.com"
        run: |
          set -euxo pipefail
          git config user.name  "$GH_USER_NAME"
          git config user.email "$GH_USER_EMAIL"
          mkdir -p data/raw/nflverse
          git add -A -f data/raw/nflverse || true
          git add -A -f models/pregame     || true
          git add -A -f output/models      || true
          git add -A -f output/predictions || true
          git add -A -f data/predictions   || true
          git diff --staged --quiet || git commit -m "CI: add/update raw artifacts, models, metrics, predictions"
          git fetch origin "${{ github.ref_name }}"
          git pull --ff-only origin "${{ github.ref_name }}" || true
          git push origin HEAD:${{ github.ref_name }} || true

      # ===== Always publish logs & final summary =====
      - name: Finalize summary
        if: always()
        run: |
          {
            echo ""
            echo "STEP OUTCOMES:"
            echo " - Step 02 (Build features): ${{ steps.Step_02__Build_features.outcome }}"
            echo " - Step 03 (Train models):  ${{ steps.Step_03__Train_models.outcome }}"
            echo " - Step 04 (Predict):       ${{ steps.Step_04__Pregame_predictions.outcome }}"
          } >> "$SUMMARY_FILE"

      - name: Upload pipeline logs (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_id }}
          path: output/_logs
